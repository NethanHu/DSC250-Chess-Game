{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:15:04.219155Z",
     "start_time": "2025-02-25T03:14:57.384334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import chess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from flatbuffers.packer import float32\n",
    "from tensorflow.python.keras.backend import learning_phase\n",
    "\n",
    "import encoding_tools as EncodingTools\n",
    "\n",
    "from model import ChessNet\n",
    "from train import train\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "MODE = \"DEBUG\"  # If in release mode, please comment this line\n",
    "# MODE = \"RELEASE\""
   ],
   "id": "22ee2c85cbe32b01",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:15:06.796749Z",
     "start_time": "2025-02-25T03:15:05.561378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pulling in training data using Pandas\n",
    "train_df = pd.read_csv('datasets/train.csv', index_col='id')\n",
    "\n",
    "train_df = train_df[:10000] if MODE == \"DEBUG\" else train_df[:25000]\n",
    "\n",
    "# We'll also grab the last 1000 examples as a validation set\n",
    "val_df = train_df[-1000:]\n",
    "\n",
    "# We'll stack all our encoded boards into a single numpy array\n",
    "X_train = np.stack(train_df['board'].apply(EncodingTools.encode_fen_string))\n",
    "y_train = train_df['black_score']\n",
    "\n",
    "X_val = np.stack(val_df['board'].apply(EncodingTools.encode_fen_string))\n",
    "y_val = val_df['black_score']"
   ],
   "id": "1707963948329279",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:16:55.424124Z",
     "start_time": "2025-02-25T03:16:55.262005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Instantiate the model\n",
    "model = ChessNet()\n",
    "\n",
    "# Move tensors to device if CUDA or MPS is available\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "# elif torch.mps.is_available():\n",
    "#     device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "model = model.to(device)"
   ],
   "id": "8226f82fc903906f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:16:57.285293Z",
     "start_time": "2025-02-25T03:16:57.240384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Custom Dataset class to handle X and y pairs\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "my_dtype = torch.float32\n",
    "\n",
    "# Convert training and validation data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=my_dtype)\n",
    "print(\"X_train_tensor shape:\", X_train_tensor.shape) if MODE == \"DEBUG\" else None\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=my_dtype).unsqueeze(1)  # Add extra dimension for compatibility\n",
    "print(\"Y_train_tensor shape:\", y_train_tensor.shape) if MODE == \"DEBUG\" else None\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=my_dtype)\n",
    "print(\"X_val_tensor shape:\", X_val_tensor.shape) if MODE == \"DEBUG\" else None\n",
    "\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=my_dtype).unsqueeze(1)  # Add extra dimension for compatibility\n",
    "print(\"Y_val_tensor shape:\", y_val_tensor.shape) if MODE == \"DEBUG\" else None\n",
    "\n",
    "# Create Dataset objects for training and validation\n",
    "train_dataset = ChessDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = ChessDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "# Create DataLoaders for batching\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "X_train_tensor, y_train_tensor = X_train_tensor.to(device), y_train_tensor.to(device)\n",
    "X_val_tensor, y_val_tensor = X_val_tensor.to(device), y_val_tensor.to(device)"
   ],
   "id": "71f6a4eefee50736",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor shape: torch.Size([10000, 8, 8, 13])\n",
      "Y_train_tensor shape: torch.Size([10000, 1])\n",
      "X_val_tensor shape: torch.Size([1000, 8, 8, 13])\n",
      "Y_val_tensor shape: torch.Size([1000, 1])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:17:35.431677Z",
     "start_time": "2025-02-25T03:17:00.120396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "n_epochs = 40\n",
    "learning_rate = 0.001\n",
    "train_losses, val_losses = [], []\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss().to(device)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    epoch_train_loss = 0\n",
    "\n",
    "    for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{n_epochs} [Training]\"):\n",
    "        X_batch = X_batch.permute(0, 3, 1, 2).to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        # Change from [batch_size, height, width, channels] to [batch_size, channels, height, width]\n",
    "        # print(\"X_batch shape:\", X_batch.shape) if MODE == \"DEBUG\" else None\n",
    "        # print(\"Y_batch shape:\", y_batch.shape) if MODE == \"DEBUG\" else None\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_batch)\n",
    "        loss = loss_fn(predictions, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "    # Average training loss for the epoch\n",
    "    train_losses.append(epoch_train_loss / len(train_loader))\n",
    "    print(f\"Epoch {epoch + 1}: Training Loss = {train_losses[-1]}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    epoch_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{n_epochs} [Validation]\"):\n",
    "            predictions = model(X_batch)\n",
    "            loss = loss_fn(predictions, y_batch)\n",
    "            epoch_val_loss += loss.item()\n",
    "\n",
    "    # Average validation loss for the epoch\n",
    "    val_losses.append(epoch_val_loss / len(val_loader))\n",
    "    print(f\"Epoch {epoch + 1}: Validation Loss = {val_losses[-1]}\")"
   ],
   "id": "d2dff1fb779ee71c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 [Training]:  12%|█▎        | 5/40 [00:34<04:03,  6.97s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 22\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Change from [batch_size, height, width, channels] to [batch_size, channels, height, width]\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# print(\"X_batch shape:\", X_batch.shape) if MODE == \"DEBUG\" else None\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# print(\"Y_batch shape:\", y_batch.shape) if MODE == \"DEBUG\" else None\u001B[39;00m\n\u001B[1;32m     21\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 22\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(predictions, y_batch)\n\u001B[1;32m     24\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/PycharmProjects/DSC250Project/model.py:123\u001B[0m, in \u001B[0;36mChessNet.forward\u001B[0;34m(self, s)\u001B[0m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;66;03m# 经过 ConvBlock 之后 (batch_size, 22, 8, 8) -> (batch_size, 256, 8, 8)\u001B[39;00m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m block \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m19\u001B[39m):\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m# 定义 19 层的 ResNet，但是每层都不会添加新的通道数\u001B[39;00m\n\u001B[1;32m    122\u001B[0m     \u001B[38;5;66;03m# (batch_size, 256, 8, 8) -> (batch_size, 256, 8, 8)\u001B[39;00m\n\u001B[0;32m--> 123\u001B[0m     s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mres_\u001B[39;49m\u001B[38;5;132;43;01m%i\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m%\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mblock\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    124\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutblock(s)\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m s\n",
      "File \u001B[0;32m/opt/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/PycharmProjects/DSC250Project/model.py:68\u001B[0m, in \u001B[0;36mResBlock.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     66\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv1(x)\n\u001B[1;32m     67\u001B[0m out \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn1(out))\n\u001B[0;32m---> 68\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     69\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn2(out)\n\u001B[1;32m     70\u001B[0m out \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m residual\n",
      "File \u001B[0;32m/opt/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/modules/conv.py:554\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    553\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 554\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/modules/conv.py:549\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    537\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    538\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(\n\u001B[1;32m    539\u001B[0m         F\u001B[38;5;241m.\u001B[39mpad(\n\u001B[1;32m    540\u001B[0m             \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    547\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups,\n\u001B[1;32m    548\u001B[0m     )\n\u001B[0;32m--> 549\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    550\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\n\u001B[1;32m    551\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plotting results (optional)\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss During Training')\n",
    "plt.show()"
   ],
   "id": "c9aebafac7b79c3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Implementing our model as a function\n",
    "def play_nn(fen, show_move_evaluations=False):\n",
    "    # We can create a python-chess board instance from the FEN string like this:\n",
    "    board = chess.Board(fen=fen)\n",
    "\n",
    "    # And then evaluate all legal moves\n",
    "    moves = []\n",
    "    input_vectors = []\n",
    "    for move in board.legal_moves:\n",
    "        # For each move, we'll make a copy of the board and try that move out\n",
    "        candidate_board = board.copy()\n",
    "        candidate_board.push(move)\n",
    "        moves.append(move)\n",
    "        input_vectors.append(EncodingTools.encode_board(str(candidate_board)).astype(np.int32).flatten())\n",
    "\n",
    "    input_vectors = np.stack(input_vectors)\n",
    "    # This is where our model gets to shine! It tells us how good the resultant score board is for black:\n",
    "    scores = model.predict(input_vectors, verbose=0)\n",
    "    # argmax gives us the index of the highest scoring move\n",
    "    if board.turn == chess.BLACK:\n",
    "        index_of_best_move = np.argmax(scores)\n",
    "    else:\n",
    "        # If we're playing as white, we want black's score to be as small as possible, so we take argmax of the negative of our array\n",
    "        index_of_best_move = np.argmax(-scores)\n",
    "\n",
    "    if show_move_evaluations:\n",
    "        print(zip(moves, scores))\n",
    "\n",
    "    best_move = moves[index_of_best_move]\n",
    "\n",
    "    # Now we turn our move into a string, return it and call it a day!\n",
    "    return str(best_move)"
   ],
   "id": "7ab0aa49445de11a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Now we'll import our test set, and make some final predictions!\n",
    "\n",
    "test_df = pd.read_csv('datasets/test.csv')\n",
    "\n",
    "test_df.head()"
   ],
   "id": "40163132028dcc88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Making all of our predictions happens in this one line!\n",
    "# We're basically saying \"run play_nn on all the boards in the test_df, and then keep the results as best_move\"\n",
    "# Because this invovles running our model a _ton_ this step will take a while.\n",
    "\n",
    "test_df['best_move'] = test_df['board'].apply(play_nn)"
   ],
   "id": "bdc8a49c80de29d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "test_df['best_move']",
   "id": "1b12d23e2131c648"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Let's make sure our submission looks like the sample submission\n",
    "submission = test_df[['id', 'best_move']]\n",
    "print(submission.head())\n",
    "\n",
    "sample_submission = pd.read_csv('datasets/sample_submission.csv', index_col='id')\n",
    "print(sample_submission.head())"
   ],
   "id": "de3782225dd02164"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# We should not output the submission file\n",
    "# submission.to_csv('submission.csv', index=False)"
   ],
   "id": "ca223917f27396f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5074d92b94c55a2d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
