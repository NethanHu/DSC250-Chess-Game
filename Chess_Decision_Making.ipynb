{
 "cells": [
  {
   "cell_type": "code",
   "id": "22ee2c85cbe32b01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T20:18:09.347126Z",
     "start_time": "2025-02-25T20:18:08.029136Z"
    }
   },
   "source": [
    "import chess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#from flatbuffers.packer import float32\n",
    "#from tensorflow.python.keras.backend import learning_phase\n",
    "\n",
    "import encoding_tools as EncodingTools\n",
    "\n",
    "from model import ChessNet\n",
    "from train import train\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "MODE = \"DEBUG\"  # If in release mode, please comment this line\n",
    "# MODE = \"RELEASE\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "1707963948329279",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T20:36:02.467480Z",
     "start_time": "2025-02-25T20:36:01.624171Z"
    }
   },
   "source": [
    "from FEN_to_chessboard import FenToChessBoard\n",
    "from encoder_decoder import encode_board\n",
    "# Pulling in training data using Pandas\n",
    "df = pd.concat([\n",
    "    pd.read_csv('stockfish_data/chess_games_1.csv'),\n",
    "    pd.read_csv('stockfish_data/chess_games_2.csv'),\n",
    "    pd.read_csv('stockfish_data/chess_games_2.csv')]\n",
    ")\n",
    "\n",
    "non_zero_winners = df[df['Winner'] != 0]\n",
    "print(\"Game with an existed winner:\", non_zero_winners.shape) # (18830, 4)\n",
    "\n",
    "train_df = non_zero_winners[:5000] if MODE == \"DEBUG\" else non_zero_winners[:16000]\n",
    "# We'll also grab the last 1000 examples as a validation set\n",
    "val_df = non_zero_winners[-1000:] if MODE == \"DEBUG\" else non_zero_winners[-2800:]\n",
    "\n",
    "# We'll stack all our encoded boards into a single numpy array\n",
    "X_train_cur_board = np.stack(train_df['FEN'].apply(FenToChessBoard.fen_to_board))\n",
    "X_train = np.stack(train_df['FEN'].apply(FenToChessBoard.fen_to_board).apply(encode_board)).reshape(-1, 22, 8, 8)\n",
    "y_train = {'best_move' : train_df['BestMove'], 'winner' : train_df['Winner']}\n",
    "\n",
    "X_val_cur_board = np.stack(val_df['FEN'].apply(FenToChessBoard.fen_to_board))\n",
    "X_val = np.stack(val_df['FEN'].apply(FenToChessBoard.fen_to_board).apply(encode_board)).reshape(-1, 22, 8, 8)\n",
    "y_val = {'best_move' : val_df['BestMove'], 'winner' : val_df['Winner']}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game with an existed winner: (18830, 4)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "8226f82fc903906f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T20:36:03.861280Z",
     "start_time": "2025-02-25T20:36:03.692214Z"
    }
   },
   "source": [
    "# Instantiate the model\n",
    "model = ChessNet()\n",
    "\n",
    "# Move tensors to device if CUDA or MPS is available\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "# elif torch.mps.is_available(): # For M series chips of Mac\n",
    "#     device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "model = model.to(device)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "71f6a4eefee50736",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T20:52:00.520824Z",
     "start_time": "2025-02-25T20:51:59.829898Z"
    }
   },
   "source": [
    "# Custom Dataset class to handle X and y pairs\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, X, param_dict):\n",
    "        self.X = X\n",
    "        self.best_move = param_dict['best_move'] # 需要进行 embedding -> [73, 8, 8]\n",
    "        self.winner = param_dict['winner']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X_tensor = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        # 将 best_move 和 winner 转为张量\n",
    "        best_move_tensor = torch.tensor(self.best_move[idx], dtype=torch.float32)\n",
    "        winner_tensor = torch.tensor(self.winner[idx], dtype=torch.int8)\n",
    "        # 返回 X[idx] 和处理后的张量\n",
    "        return X_tensor, (best_move_tensor, winner_tensor)\n",
    "        # return self.X[idx], (self.best_move[idx], self.winner[idx])\n",
    "\n",
    "\n",
    "# Create Dataset objects for training and validation\n",
    "train_dataset = ChessDataset(X_train, y_train)\n",
    "val_dataset = ChessDataset(X_val, y_val)\n",
    "\n",
    "# Create DataLoaders for batching\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for X_batch, y_batch in train_loader:\n",
    "    # 获取一个批次的数据\n",
    "    best_move_batch, winner_batch = y_batch  # 拆分 y_batch\n",
    "    print(\"X_batch shape:\", X_batch.shape)  # 打印 X 的维度\n",
    "    print(\"best_move shape:\", best_move_batch.shape)  # 打印 best_move 的维度\n",
    "    print(\"winner shape:\", winner_batch.shape)  # 打印 winner 的维度\n",
    "    break  # 打印一个批次后停止"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "920",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m/opt/anaconda3/envs/chess/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 920",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 30\u001B[0m\n\u001B[1;32m     27\u001B[0m train_loader \u001B[38;5;241m=\u001B[39m DataLoader(train_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     28\u001B[0m val_loader \u001B[38;5;241m=\u001B[39m DataLoader(val_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m---> 30\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m X_batch, y_batch \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;66;03m# 获取一个批次的数据\u001B[39;00m\n\u001B[1;32m     32\u001B[0m     best_move_batch, winner_batch \u001B[38;5;241m=\u001B[39m y_batch  \u001B[38;5;66;03m# 拆分 y_batch\u001B[39;00m\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX_batch shape:\u001B[39m\u001B[38;5;124m\"\u001B[39m, X_batch\u001B[38;5;241m.\u001B[39mshape)  \u001B[38;5;66;03m# 打印 X 的维度\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/chess/lib/python3.10/site-packages/torch/utils/data/dataloader.py:708\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    705\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    707\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 708\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    709\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    710\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    711\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[1;32m    712\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    713\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[1;32m    714\u001B[0m ):\n",
      "File \u001B[0;32m/opt/anaconda3/envs/chess/lib/python3.10/site-packages/torch/utils/data/dataloader.py:764\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    762\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    763\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 764\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    765\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    766\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/chess/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m/opt/anaconda3/envs/chess/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Cell \u001B[0;32mIn[22], line 14\u001B[0m, in \u001B[0;36mChessDataset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m     12\u001B[0m X_tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX[idx], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# 将 best_move 和 winner 转为张量\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m best_move_tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbest_move\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m     15\u001B[0m winner_tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwinner[idx], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mint8)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# 返回 X[idx] 和处理后的张量\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/chess/lib/python3.10/site-packages/pandas/core/series.py:1121\u001B[0m, in \u001B[0;36mSeries.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   1118\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[key]\n\u001B[1;32m   1120\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m key_is_scalar:\n\u001B[0;32m-> 1121\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1123\u001B[0m \u001B[38;5;66;03m# Convert generator to list before going through hashable part\u001B[39;00m\n\u001B[1;32m   1124\u001B[0m \u001B[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001B[39;00m\n\u001B[1;32m   1125\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n",
      "File \u001B[0;32m/opt/anaconda3/envs/chess/lib/python3.10/site-packages/pandas/core/series.py:1237\u001B[0m, in \u001B[0;36mSeries._get_value\u001B[0;34m(self, label, takeable)\u001B[0m\n\u001B[1;32m   1234\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[label]\n\u001B[1;32m   1236\u001B[0m \u001B[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001B[39;00m\n\u001B[0;32m-> 1237\u001B[0m loc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1239\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(loc):\n\u001B[1;32m   1240\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[loc]\n",
      "File \u001B[0;32m/opt/anaconda3/envs/chess/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[1;32m   3810\u001B[0m     ):\n\u001B[1;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 920"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "d2dff1fb779ee71c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T19:27:31.172558Z",
     "start_time": "2025-02-25T19:27:30.276608Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "n_epochs = 40\n",
    "learning_rate = 0.001\n",
    "train_losses, val_losses = [], []\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss().to(device)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    epoch_train_loss = 0\n",
    "\n",
    "    for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{n_epochs} [Training]\"):\n",
    "        X_batch = X_batch.permute(0, 3, 1, 2).to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        # Change from [batch_size, height, width, channels] to [batch_size, channels, height, width]\n",
    "        # print(\"X_batch shape:\", X_batch.shape) if MODE == \"DEBUG\" else None\n",
    "        # print(\"Y_batch shape:\", y_batch.shape) if MODE == \"DEBUG\" else None\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_batch)\n",
    "        loss = loss_fn(predictions, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "    # Average training loss for the epoch\n",
    "    train_losses.append(epoch_train_loss / len(train_loader))\n",
    "    print(f\"Epoch {epoch + 1}: Training Loss = {train_losses[-1]}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    epoch_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{n_epochs} [Validation]\"):\n",
    "            predictions = model(X_batch)\n",
    "            loss = loss_fn(predictions, y_batch)\n",
    "            epoch_val_loss += loss.item()\n",
    "\n",
    "    # Average validation loss for the epoch\n",
    "    val_losses.append(epoch_val_loss / len(val_loader))\n",
    "    print(f\"Epoch {epoch + 1}: Validation Loss = {val_losses[-1]}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 [Training]:   0%|          | 0/40 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 13, 8, 8])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 22, 8, 8]' is invalid for input of size 212992",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 22\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Change from [batch_size, height, width, channels] to [batch_size, channels, height, width]\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# print(\"X_batch shape:\", X_batch.shape) if MODE == \"DEBUG\" else None\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# print(\"Y_batch shape:\", y_batch.shape) if MODE == \"DEBUG\" else None\u001B[39;00m\n\u001B[1;32m     21\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 22\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(predictions, y_batch)\n\u001B[1;32m     24\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/PycharmProjects/DSC250Project/model.py:119\u001B[0m, in \u001B[0;36mChessNet.forward\u001B[0;34m(self, s)\u001B[0m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m,s):\n\u001B[1;32m    117\u001B[0m     \u001B[38;5;66;03m# 来自于数据集，经过 BoardData 数据加载器加载后的数据\u001B[39;00m\n\u001B[1;32m    118\u001B[0m     \u001B[38;5;66;03m# 一开始的形状可能是 (batch_size, 22, 8, 8)\u001B[39;00m\n\u001B[0;32m--> 119\u001B[0m     s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;66;03m# 经过 ConvBlock 之后 (batch_size, 22, 8, 8) -> (batch_size, 256, 8, 8)\u001B[39;00m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m block \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m19\u001B[39m):\n\u001B[1;32m    122\u001B[0m         \u001B[38;5;66;03m# 定义 19 层的 ResNet，但是每层都不会添加新的通道数\u001B[39;00m\n\u001B[1;32m    123\u001B[0m         \u001B[38;5;66;03m# (batch_size, 256, 8, 8) -> (batch_size, 256, 8, 8)\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/chess/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/PycharmProjects/DSC250Project/model.py:48\u001B[0m, in \u001B[0;36mConvBlock.forward\u001B[0;34m(self, s)\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28mprint\u001B[39m(s\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m     46\u001B[0m \u001B[38;5;66;03m# s = s.reshape(-1, 13, 8, 8)  # batch_size x channels x board_x x board_y\u001B[39;00m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;66;03m# s = F.relu(self.bn0(self.conv0(s)))\u001B[39;00m\n\u001B[0;32m---> 48\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[43ms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m22\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# batch_size x channels x board_x x board_y\u001B[39;00m\n\u001B[1;32m     49\u001B[0m s \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn1(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv1(s)))\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m s\n",
      "\u001B[0;31mRuntimeError\u001B[0m: shape '[-1, 22, 8, 8]' is invalid for input of size 212992"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "c9aebafac7b79c3c",
   "metadata": {},
   "source": [
    "# Plotting results (optional)\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss During Training')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab0aa49445de11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing our model as a function\n",
    "def play_nn(fen, show_move_evaluations=False):\n",
    "    # We can create a python-chess board instance from the FEN string like this:\n",
    "    board = chess.Board(fen=fen)\n",
    "\n",
    "    # And then evaluate all legal moves\n",
    "    moves = []\n",
    "    input_vectors = []\n",
    "    for move in board.legal_moves:\n",
    "        # For each move, we'll make a copy of the board and try that move out\n",
    "        candidate_board = board.copy()\n",
    "        candidate_board.push(move)\n",
    "        moves.append(move)\n",
    "        input_vectors.append(EncodingTools.encode_board(str(candidate_board)).astype(np.int32).flatten())\n",
    "\n",
    "    input_vectors = np.stack(input_vectors)\n",
    "    # This is where our model gets to shine! It tells us how good the resultant score board is for black:\n",
    "    scores = model.predict(input_vectors, verbose=0)\n",
    "    # argmax gives us the index of the highest scoring move\n",
    "    if board.turn == chess.BLACK:\n",
    "        index_of_best_move = np.argmax(scores)\n",
    "    else:\n",
    "        # If we're playing as white, we want black's score to be as small as possible, so we take argmax of the negative of our array\n",
    "        index_of_best_move = np.argmax(-scores)\n",
    "\n",
    "    if show_move_evaluations:\n",
    "        print(zip(moves, scores))\n",
    "\n",
    "    best_move = moves[index_of_best_move]\n",
    "\n",
    "    # Now we turn our move into a string, return it and call it a day!\n",
    "    return str(best_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40163132028dcc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll import our test set, and make some final predictions!\n",
    "\n",
    "test_df = pd.read_csv('datasets/test.csv')\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc8a49c80de29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making all of our predictions happens in this one line!\n",
    "# We're basically saying \"run play_nn on all the boards in the test_df, and then keep the results as best_move\"\n",
    "# Because this invovles running our model a _ton_ this step will take a while.\n",
    "\n",
    "test_df['best_move'] = test_df['board'].apply(play_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b12d23e2131c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['best_move']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3782225dd02164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make sure our submission looks like the sample submission\n",
    "submission = test_df[['id', 'best_move']]\n",
    "print(submission.head())\n",
    "\n",
    "sample_submission = pd.read_csv('datasets/sample_submission.csv', index_col='id')\n",
    "print(sample_submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca223917f27396f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should not output the submission file\n",
    "# submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5074d92b94c55a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "warm-up",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
