{
 "cells": [
  {
   "cell_type": "code",
   "id": "22ee2c85cbe32b01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T05:03:03.689782Z",
     "start_time": "2025-02-26T05:03:02.470775Z"
    }
   },
   "source": [
    "import chess\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import encoding_tools as EncodingTools\n",
    "\n",
    "from model import ChessNet\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "MODE = \"DEBUG\"  # If in release mode, please comment this line\n",
    "# MODE = \"RELEASE\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "1707963948329279",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T05:03:07.689846Z",
     "start_time": "2025-02-26T05:03:06.144286Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "from FEN_to_chessboard import FenToChessBoard\n",
    "from encoder_decoder import *\n",
    "\n",
    "# Pulling in training data using Pandas\n",
    "df = pd.concat([\n",
    "    pd.read_csv('stockfish_data/chess_games_1.csv'),\n",
    "    pd.read_csv('stockfish_data/chess_games_2.csv'),\n",
    "    pd.read_csv('stockfish_data/chess_games_2.csv')]\n",
    ")\n",
    "\n",
    "non_zero_winners = df[df['Winner'] != 0].copy()\n",
    "non_zero_winners.reset_index(drop=True, inplace=True)\n",
    "print(\"Game with an existed winner:\", non_zero_winners.shape) # (18830, 4)\n",
    "\n",
    "train_df = non_zero_winners[:5000] if MODE == \"DEBUG\" else non_zero_winners[:16000]\n",
    "# We'll also grab the last 1000 examples as a validation set\n",
    "val_df = non_zero_winners[-1000:] if MODE == \"DEBUG\" else non_zero_winners[-2800:]\n",
    "\n",
    "##### Package the training data\n",
    "\n",
    "X_train = np.stack(train_df['FEN'].apply(FenToChessBoard.fen_to_board).apply(encode_board)).reshape(-1, 22, 8, 8) # Size(5000, 22, 8, 8)\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "\n",
    "train_best_move_embedding = []\n",
    "for idx, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"[TrainSet] BestMove to embedding\"):\n",
    "    fen_str = row['FEN']\n",
    "    move_str = row['BestMove']\n",
    "    # Check if fen_str is a valid string before processing\n",
    "    if not isinstance(fen_str, str):\n",
    "        raise ValueError(f\"Invalid FEN string at index {idx}: {fen_str}\")\n",
    "    board = FenToChessBoard.fen_to_board(fen_str)\n",
    "    train_best_move_embedding.append(move_on_board(board, move_str))\n",
    "train_best_move_embedding = np.array(train_best_move_embedding)\n",
    "print(\"Embedded Best move shape:\", train_best_move_embedding.shape)\n",
    "y_train = {'best_move' : train_best_move_embedding, 'winner' : train_df['Winner']}\n",
    "\n",
    "\n",
    "##### Package the validation data\n",
    "\n",
    "X_val = np.stack(val_df['FEN'].apply(FenToChessBoard.fen_to_board).apply(encode_board)).reshape(-1, 22, 8, 8)\n",
    "print(\"Validation set size:\", X_val.shape)\n",
    "\n",
    "val_best_move_embedding = []\n",
    "for idx, row in tqdm(val_df.iterrows(), total=len(val_df), desc=\"[ValSet] BestMove to embedding\"):\n",
    "    fen_str = row['FEN']\n",
    "    move_str = row['BestMove']\n",
    "    # Check if fen_str is a valid string before processing\n",
    "    if not isinstance(fen_str, str):\n",
    "        raise ValueError(f\"Invalid FEN string at index {idx}: {fen_str}\")\n",
    "    board = FenToChessBoard.fen_to_board(fen_str)\n",
    "    val_best_move_embedding.append(move_on_board(board, move_str))\n",
    "val_best_move_embedding = np.array(val_best_move_embedding)\n",
    "X_val_cur_board = np.stack(val_df['FEN'].apply(FenToChessBoard.fen_to_board))\n",
    "y_val = {'best_move' : val_best_move_embedding, 'winner' : val_df['Winner']}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game with an existed winner: (18830, 4)\n",
      "Training set size: (5000, 22, 8, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TrainSet] BestMove to embedding: 100%|██████████| 5000/5000 [00:00<00:00, 10658.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded Best move shape: (5000, 4672)\n",
      "Validation set size: (1000, 22, 8, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ValSet] BestMove to embedding: 100%|██████████| 1000/1000 [00:00<00:00, 5826.39it/s]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "8226f82fc903906f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T05:03:12.125294Z",
     "start_time": "2025-02-26T05:03:11.964941Z"
    }
   },
   "source": [
    "# Instantiate the model\n",
    "model = ChessNet()\n",
    "\n",
    "# Move tensors to device if CUDA or MPS is available\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "# elif torch.mps.is_available(): # For M series chips of Mac\n",
    "#     device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "model = model.to(device)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "71f6a4eefee50736",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T05:03:13.996488Z",
     "start_time": "2025-02-26T05:03:13.978994Z"
    }
   },
   "source": [
    "from model import ChessDataset\n",
    "\n",
    "# Create Dataset objects for training and validation\n",
    "train_dataset = ChessDataset(X_train, y_train)\n",
    "val_dataset = ChessDataset(X_val, y_val)\n",
    "\n",
    "# Create DataLoaders for batching\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for X_batch, y_batch in train_loader:\n",
    "    # 获取一个批次的数据\n",
    "    best_move_batch, winner_batch = y_batch  # 拆分 y_batch\n",
    "    print(\"X_batch shape:\", X_batch.shape)  # 打印 X 的维度\n",
    "    print(\"best_move shape:\", best_move_batch.shape)  # 打印 best_move 的维度\n",
    "    print(\"winner shape:\", winner_batch.shape)  # 打印 winner 的维度\n",
    "    break  # 打印一个批次后停止"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch shape: torch.Size([256, 22, 8, 8])\n",
      "best_move shape: torch.Size([256, 4672])\n",
      "winner shape: torch.Size([256])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "d2dff1fb779ee71c",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-02-26T05:04:11.879658Z",
     "start_time": "2025-02-26T05:03:16.852411Z"
    }
   },
   "source": [
    "import torch.optim as optim\n",
    "from train import AlphaLoss\n",
    "\n",
    "n_epochs = 40\n",
    "learning_rate = 0.003\n",
    "train_losses, val_losses = [], []\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = AlphaLoss().to(device)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    epoch_train_loss = 0\n",
    "\n",
    "    for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{n_epochs} [Training]\"):\n",
    "        # print(\"Size of X_batch:\", X_batch.shape)\n",
    "        # print(\"Size of p in Y_batch:\", y_batch[0].shape)\n",
    "        # print(\"Size of v in Y_batch:\", y_batch[1].shape)\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_p = y_batch[0].to(device)\n",
    "        y_v = y_batch[1].to(device).reshape(-1, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_batch)\n",
    "        # print(\"Size of p in predictions:\", predictions['p'].shape)\n",
    "        # print(\"Size of v in predictions:\", predictions['v'].shape)\n",
    "        loss = loss_fn(y_v, predictions['v'], y_p, predictions['p'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "    # Average training loss for the epoch\n",
    "    train_losses.append(epoch_train_loss / len(train_loader))\n",
    "    print(f\"Epoch {epoch + 1}: Training Loss = {train_losses[-1]}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    epoch_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{n_epochs} [Validation]\"):\n",
    "            predictions = model(X_batch)\n",
    "            loss = loss_fn(predictions, y_batch)\n",
    "            epoch_val_loss += loss.item()\n",
    "\n",
    "    # Average validation loss for the epoch\n",
    "    val_losses.append(epoch_val_loss / len(val_loader))\n",
    "    print(f\"Epoch {epoch + 1}: Validation Loss = {val_losses[-1]}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 [Training]:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_batch: torch.Size([256, 22, 8, 8])\n",
      "Size of p in Y_batch: torch.Size([256, 4672])\n",
      "Size of v in Y_batch: torch.Size([256])\n",
      "Size of input to ConvBlock: torch.Size([256, 22, 8, 8])\n",
      "Size of p in predictions: torch.Size([256, 4672])\n",
      "Size of v in predictions: torch.Size([256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 [Training]:   5%|▌         | 1/20 [00:06<02:03,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_batch: torch.Size([256, 22, 8, 8])\n",
      "Size of p in Y_batch: torch.Size([256, 4672])\n",
      "Size of v in Y_batch: torch.Size([256])\n",
      "Size of input to ConvBlock: torch.Size([256, 22, 8, 8])\n",
      "Size of p in predictions: torch.Size([256, 4672])\n",
      "Size of v in predictions: torch.Size([256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 [Training]:  10%|█         | 2/20 [00:13<02:03,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_batch: torch.Size([256, 22, 8, 8])\n",
      "Size of p in Y_batch: torch.Size([256, 4672])\n",
      "Size of v in Y_batch: torch.Size([256])\n",
      "Size of input to ConvBlock: torch.Size([256, 22, 8, 8])\n",
      "Size of p in predictions: torch.Size([256, 4672])\n",
      "Size of v in predictions: torch.Size([256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 [Training]:  15%|█▌        | 3/20 [00:22<02:11,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_batch: torch.Size([256, 22, 8, 8])\n",
      "Size of p in Y_batch: torch.Size([256, 4672])\n",
      "Size of v in Y_batch: torch.Size([256])\n",
      "Size of input to ConvBlock: torch.Size([256, 22, 8, 8])\n",
      "Size of p in predictions: torch.Size([256, 4672])\n",
      "Size of v in predictions: torch.Size([256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 [Training]:  20%|██        | 4/20 [00:32<02:17,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_batch: torch.Size([256, 22, 8, 8])\n",
      "Size of p in Y_batch: torch.Size([256, 4672])\n",
      "Size of v in Y_batch: torch.Size([256])\n",
      "Size of input to ConvBlock: torch.Size([256, 22, 8, 8])\n",
      "Size of p in predictions: torch.Size([256, 4672])\n",
      "Size of v in predictions: torch.Size([256, 1])\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c9aebafac7b79c3c",
   "metadata": {},
   "source": [
    "# Plotting results (optional)\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss During Training')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab0aa49445de11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing our model as a function\n",
    "def play_nn(fen, show_move_evaluations=False):\n",
    "    # We can create a python-chess board instance from the FEN string like this:\n",
    "    board = chess.Board(fen=fen)\n",
    "\n",
    "    # And then evaluate all legal moves\n",
    "    moves = []\n",
    "    input_vectors = []\n",
    "    for move in board.legal_moves:\n",
    "        # For each move, we'll make a copy of the board and try that move out\n",
    "        candidate_board = board.copy()\n",
    "        candidate_board.push(move)\n",
    "        moves.append(move)\n",
    "        input_vectors.append(EncodingTools.encode_board(str(candidate_board)).astype(np.int32).flatten())\n",
    "\n",
    "    input_vectors = np.stack(input_vectors)\n",
    "    # This is where our model gets to shine! It tells us how good the resultant score board is for black:\n",
    "    scores = model.predict(input_vectors, verbose=0)\n",
    "    # argmax gives us the index of the highest scoring move\n",
    "    if board.turn == chess.BLACK:\n",
    "        index_of_best_move = np.argmax(scores)\n",
    "    else:\n",
    "        # If we're playing as white, we want black's score to be as small as possible, so we take argmax of the negative of our array\n",
    "        index_of_best_move = np.argmax(-scores)\n",
    "\n",
    "    if show_move_evaluations:\n",
    "        print(zip(moves, scores))\n",
    "\n",
    "    best_move = moves[index_of_best_move]\n",
    "\n",
    "    # Now we turn our move into a string, return it and call it a day!\n",
    "    return str(best_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40163132028dcc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll import our test set, and make some final predictions!\n",
    "\n",
    "test_df = pd.read_csv('datasets/test.csv')\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc8a49c80de29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making all of our predictions happens in this one line!\n",
    "# We're basically saying \"run play_nn on all the boards in the test_df, and then keep the results as best_move\"\n",
    "# Because this invovles running our model a _ton_ this step will take a while.\n",
    "\n",
    "test_df['best_move'] = test_df['board'].apply(play_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b12d23e2131c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['best_move']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3782225dd02164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make sure our submission looks like the sample submission\n",
    "submission = test_df[['id', 'best_move']]\n",
    "print(submission.head())\n",
    "\n",
    "sample_submission = pd.read_csv('datasets/sample_submission.csv', index_col='id')\n",
    "print(sample_submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca223917f27396f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should not output the submission file\n",
    "# submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5074d92b94c55a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "warm-up",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
