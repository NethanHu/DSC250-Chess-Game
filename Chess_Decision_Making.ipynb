{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import chess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten"
   ],
   "id": "22ee2c85cbe32b01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Defining Data preparation functions\n",
    "def one_hot_encode_piece(piece):\n",
    "    pieces = list('rnbqkpRNBQKP.')\n",
    "    arr = np.zeros(len(pieces))\n",
    "    piece_to_index = {p: i for i, p in enumerate(pieces)}\n",
    "    index = piece_to_index[piece]\n",
    "    arr[index] = 1\n",
    "    return arr\n",
    "\n",
    "def encode_board(board):\n",
    "    # first lets turn the board into a string\n",
    "    board_str = str(board)\n",
    "    # then lets remove all the spaces\n",
    "    board_str = board_str.replace(' ', '')\n",
    "    board_list = []\n",
    "    for row in board_str.split('\\n'):\n",
    "        row_list = []\n",
    "        for piece in row:\n",
    "            row_list.append(one_hot_encode_piece(piece))\n",
    "        board_list.append(row_list)\n",
    "    return np.array(board_list)\n",
    "\n",
    "def encode_fen_string(fen_str):\n",
    "    board = chess.Board(fen=fen_str)\n",
    "    return encode_board(board)"
   ],
   "id": "48dbd8a5f8227266"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Pulling in training data using Pandas\n",
    "train_df = pd.read_csv('datasets/train.csv', index_col='id')\n",
    "\n",
    "# We'll only use the first 10000 examples so things run fast,\n",
    "# but you'll get better performance if you remove this line\n",
    "train_df = train_df[:25000]\n",
    "\n",
    "# We'll also grab the last 1000 examples as a validation set\n",
    "val_df = train_df[-1000:]\n",
    "train_df.head()\n",
    "\n",
    "def encode_fen_string(fen_str):\n",
    "    board = chess.Board(fen=fen_str)\n",
    "    return encode_board(board)\n",
    "\n",
    "# We'll stack all our encoded boards into a single numpy array\n",
    "X_train = np.stack(train_df['board'].apply(encode_fen_string))\n",
    "y_train = train_df['black_score']\n",
    "\n",
    "\n",
    "X_val = np.stack(val_df['board'].apply(encode_fen_string))\n",
    "y_val = val_df['black_score']"
   ],
   "id": "1707963948329279"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Creating our prediction model\n",
    "# With the Keras Sequential model we can stack neural network layers like Dense, Flatten together\n",
    "model = Sequential([\n",
    "    Flatten(),\n",
    "    Dense(2048, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='mean_squared_error')"
   ],
   "id": "8226f82fc903906f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Solve the no attribute 'DistributedDatasetInterface' problem\n",
    "from tensorflow.python.keras.engine import data_adapter\n",
    "\n",
    "def _is_distributed_dataset(ds):\n",
    "    return isinstance(ds, data_adapter.input_lib.DistributedDatasetSpec)\n",
    "\n",
    "data_adapter._is_distributed_dataset = _is_distributed_dataset\n",
    "\n",
    "# To test things out, let's train for n epochs and see how our model is doing\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=40,\n",
    "    validation_data=(X_val, y_val))"
   ],
   "id": "71f6a4eefee50736"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plotting our latest training results\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.title('Loss During Training')\n",
    "plt.show()"
   ],
   "id": "c9aebafac7b79c3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Implementing our model as a function\n",
    "def play_nn(fen, show_move_evaluations=False):\n",
    "    # We can create a python-chess board instance from the FEN string like this:\n",
    "    board = chess.Board(fen=fen)\n",
    "\n",
    "    # And then evaluate all legal moves\n",
    "    moves = []\n",
    "    input_vectors = []\n",
    "    for move in board.legal_moves:\n",
    "        # For each move, we'll make a copy of the board and try that move out\n",
    "        candidate_board = board.copy()\n",
    "        candidate_board.push(move)\n",
    "        moves.append(move)\n",
    "        input_vectors.append(encode_board(str(candidate_board)).astype(np.int32).flatten())\n",
    "\n",
    "    input_vectors = np.stack(input_vectors)\n",
    "    # This is where our model gets to shine! It tells us how good the resultant score board is for black:\n",
    "    scores = model.predict(input_vectors, verbose=0)\n",
    "    # argmax gives us the index of the highest scoring move\n",
    "    if board.turn == chess.BLACK:\n",
    "        index_of_best_move = np.argmax(scores)\n",
    "    else:\n",
    "        # If we're playing as white, we want black's score to be as small as possible, so we take argmax of the negative of our array\n",
    "        index_of_best_move = np.argmax(-scores)\n",
    "\n",
    "    if show_move_evaluations:\n",
    "        print(zip(moves, scores))\n",
    "\n",
    "    best_move = moves[index_of_best_move]\n",
    "\n",
    "    # Now we turn our move into a string, return it and call it a day!\n",
    "    return str(best_move)"
   ],
   "id": "7ab0aa49445de11a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Now we'll import our test set, and make some final predictions!\n",
    "\n",
    "test_df = pd.read_csv('datasets/test.csv')\n",
    "\n",
    "test_df.head()"
   ],
   "id": "40163132028dcc88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Making all of our predictions happens in this one line!\n",
    "# We're basically saying \"run play_nn on all the boards in the test_df, and then keep the results as best_move\"\n",
    "# Because this invovles running our model a _ton_ this step will take a while.\n",
    "\n",
    "test_df['best_move'] = test_df['board'].apply(play_nn)"
   ],
   "id": "bdc8a49c80de29d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "test_df['best_move']",
   "id": "1b12d23e2131c648"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Let's make sure our submission looks like the sample submission\n",
    "submission = test_df[['id', 'best_move']]\n",
    "print(submission.head())\n",
    "\n",
    "sample_submission = pd.read_csv('datasets/sample_submission.csv', index_col='id')\n",
    "print(sample_submission.head())"
   ],
   "id": "de3782225dd02164"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "submission.to_csv('submission.csv', index=False)",
   "id": "793a96daf4c3c095"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dfa072c545b0dbec"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
