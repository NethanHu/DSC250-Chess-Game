{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d191d686-4228-4f20-a393-77b18ac29159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import encoding_tools as EncodingTools\n",
    "\n",
    "from model import ChessNet\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "MODE = \"RELEASE\"  # If in release mode, please comment this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6bb2115-0e44-4eb6-a765-e32b00c9c14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game with an existed winner: (300000, 4)\n",
      "Training set size: (270000, 22, 8, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TrainSet] BestMove to embedding: 100%|██████████| 270000/270000 [00:54<00:00, 4941.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded Best move shape: (270000, 4672)\n",
      "Validation set size: (30000, 22, 8, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ValSet] BestMove to embedding: 100%|██████████| 30000/30000 [00:05<00:00, 5064.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets are prepared, you are all set!\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from FEN_to_chessboard import FenToChessBoard\n",
    "from encoder_decoder import *\n",
    "\n",
    "# Pulling in training data using Pandas\n",
    "df = pd.concat([\n",
    "    pd.read_csv('stockfish_data/chess_games_1.csv'),\n",
    "    pd.read_csv('stockfish_data/chess_games_2.csv'),\n",
    "    pd.read_csv('stockfish_data/chess_games_2.csv')]\n",
    ")\n",
    "\n",
    "non_zero_winners = df.copy()\n",
    "# non_zero_winners = df[df['Winner'] != 0].copy()\n",
    "non_zero_winners.reset_index(drop=True, inplace=True)\n",
    "print(\"Game with an existed winner:\", non_zero_winners.shape) # (18830, 4)\n",
    "\n",
    "train_df = non_zero_winners[:5000] if MODE == \"DEBUG\" else non_zero_winners[:270000]\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "# We'll also grab the last 1000 examples as a validation set\n",
    "val_df = non_zero_winners[-1000:] if MODE == \"DEBUG\" else non_zero_winners[-30000:]\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "##### Package the training data\n",
    "\n",
    "X_train = np.stack(train_df['FEN'].apply(FenToChessBoard.fen_to_board).apply(encode_board)).reshape(-1, 22, 8, 8) # Size(5000, 22, 8, 8)\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "\n",
    "train_best_move_embedding = []\n",
    "for idx, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"[TrainSet] BestMove to embedding\"):\n",
    "    fen_str = row['FEN']\n",
    "    move_str = row['BestMove']\n",
    "    # Check if fen_str is a valid string before processing\n",
    "    if not isinstance(fen_str, str):\n",
    "        raise ValueError(f\"Invalid FEN string at index {idx}: {fen_str}\")\n",
    "    board = FenToChessBoard.fen_to_board(fen_str)\n",
    "    train_best_move_embedding.append(move_on_board(board, move_str))\n",
    "train_best_move_embedding = np.array(train_best_move_embedding)\n",
    "print(\"Embedded Best move shape:\", train_best_move_embedding.shape)\n",
    "y_train = {'best_move' : train_best_move_embedding, 'winner' : train_df['Winner']}\n",
    "\n",
    "\n",
    "##### Package the validation data\n",
    "\n",
    "X_val = np.stack(val_df['FEN'].apply(FenToChessBoard.fen_to_board).apply(encode_board)).reshape(-1, 22, 8, 8)\n",
    "print(\"Validation set size:\", X_val.shape)\n",
    "\n",
    "val_best_move_embedding = []\n",
    "for idx, row in tqdm(val_df.iterrows(), total=len(val_df), desc=\"[ValSet] BestMove to embedding\"):\n",
    "    fen_str = row['FEN']\n",
    "    move_str = row['BestMove']\n",
    "    # Check if fen_str is a valid string before processing\n",
    "    if not isinstance(fen_str, str):\n",
    "        raise ValueError(f\"Invalid FEN string at index {idx}: {fen_str}\")\n",
    "    board = FenToChessBoard.fen_to_board(fen_str)\n",
    "    val_best_move_embedding.append(move_on_board(board, move_str))\n",
    "val_best_move_embedding = np.array(val_best_move_embedding)\n",
    "X_val_cur_board = np.stack(val_df['FEN'].apply(FenToChessBoard.fen_to_board))\n",
    "y_val = {'best_move' : val_best_move_embedding, 'winner' : val_df['Winner']}\n",
    "print(\"Datasets are prepared, you are all set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10e523c7-1b66-479d-8d3b-00aa586c1d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前 GPU 型号是：NVIDIA GeForce RTX 4090，可用总显存为：25.282281472 GB\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = ChessNet()\n",
    "\n",
    "# Move tensors to device if CUDA or MPS is available\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "# elif torch.mps.is_available(): # For M series chips of Mac\n",
    "#     device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "if device == \"cuda\":\n",
    "    # 获取当前GPU名字\n",
    "    gpu_name = torch.cuda.get_device_name(torch.cuda.current_device())\n",
    "    # 获取当前GPU总显存\n",
    "    props = torch.cuda.get_device_properties(device)\n",
    "    total_memory = props.total_memory / 1e9\n",
    "\n",
    "    print(\"当前 GPU 型号是：{}，可用总显存为：{} GB\".format(gpu_name, total_memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a91df04-c5b1-4210-a14a-34bf47439e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch shape: torch.Size([3000, 22, 8, 8])\n",
      "best_move shape: torch.Size([3000, 4672])\n",
      "winner shape: torch.Size([3000])\n"
     ]
    }
   ],
   "source": [
    "from model import ChessDataset\n",
    "\n",
    "# Create Dataset objects for training and validation\n",
    "train_dataset = ChessDataset(X_train, y_train)\n",
    "val_dataset = ChessDataset(X_val, y_val)\n",
    "\n",
    "# Create DataLoaders for batching\n",
    "batch_size = 3000\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for X_batch, y_batch in train_loader:\n",
    "    # 获取一个批次的数据\n",
    "    best_move_batch, winner_batch = y_batch  # 拆分 y_batch\n",
    "    print(\"X_batch shape:\", X_batch.shape)  # 打印 X 的维度\n",
    "    print(\"best_move shape:\", best_move_batch.shape)  # 打印 best_move 的维度\n",
    "    print(\"winner shape:\", winner_batch.shape)  # 打印 winner 的维度\n",
    "    break  # 打印一个批次后停止"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e2dfe29-27aa-42cf-9dc9-c35ebc312ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 [Training]: 100%|██████████| 90/90 [00:24<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss = 1.4073289155960083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 [Validating]: 100%|██████████| 10/10 [00:01<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation Loss = 1.4023775339126587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/40 [Training]: 100%|██████████| 90/90 [00:24<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Training Loss = 1.403346840540568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/40 [Validating]: 100%|██████████| 10/10 [00:01<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Validation Loss = 1.402377474308014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/40 [Training]: 100%|██████████| 90/90 [00:24<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Training Loss = 1.40334659020106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/40 [Validating]: 100%|██████████| 10/10 [00:01<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Validation Loss = 1.4023775100708007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/40 [Training]: 100%|██████████| 90/90 [00:24<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Training Loss = 1.4033462709850735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/40 [Validating]: 100%|██████████| 10/10 [00:01<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Validation Loss = 1.4023769617080688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/40 [Training]: 100%|██████████| 90/90 [00:25<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Training Loss = 1.403346061706543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/40 [Validating]: 100%|██████████| 10/10 [00:01<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Validation Loss = 1.402376937866211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/40 [Training]: 100%|██████████| 90/90 [00:25<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Training Loss = 1.4033460524347094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/40 [Validating]: 100%|██████████| 10/10 [00:01<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Validation Loss = 1.4023769617080688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/40 [Training]: 100%|██████████| 90/90 [00:25<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Training Loss = 1.4033461570739747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/40 [Validating]: 100%|██████████| 10/10 [00:01<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Validation Loss = 1.4023770332336425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/40 [Training]: 100%|██████████| 90/90 [00:25<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Training Loss = 1.403346175617642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/40 [Validating]: 100%|██████████| 10/10 [00:01<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Validation Loss = 1.4023770689964294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/40 [Training]: 100%|██████████| 90/90 [00:25<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Training Loss = 1.403346179591285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/40 [Validating]: 100%|██████████| 10/10 [00:01<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Validation Loss = 1.4023770689964294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/40 [Training]: 100%|██████████| 90/90 [00:25<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Training Loss = 1.403346155749427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/40 [Validating]: 100%|██████████| 10/10 [00:01<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Validation Loss = 1.4023769855499268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/40 [Training]:  83%|████████▎ | 75/90 [00:21<00:04,  3.52it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m epoch_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     14\u001b[0m grads \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [Training]\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     16\u001b[0m     X_batch \u001b[38;5;241m=\u001b[39m X_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m     y_p \u001b[38;5;241m=\u001b[39m y_batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/chess/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/chess/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/chess/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/chess/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/chess/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/DSC250Project/model.py:30\u001b[0m, in \u001b[0;36mChessDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     28\u001b[0m X_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX[idx], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 将 best_move 和 winner 转为张量\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m best_move_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_move\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m winner_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwinner[idx], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint8)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# 返回 X[idx] 和处理后的张量\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from train import AlphaLoss\n",
    "\n",
    "n_epochs = 40\n",
    "learning_rate = 0.0001 # 0.003 —> 0.0001\n",
    "train_losses, val_losses = [], []\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = AlphaLoss().to(device)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    epoch_train_loss = 0\n",
    "\n",
    "    grads = {}\n",
    "    for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{n_epochs} [Training]\"):\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_p = y_batch[0].to(device)\n",
    "        y_v = y_batch[1].to(device).reshape(-1, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_batch)\n",
    "        loss = loss_fn(y_v, predictions['v'], y_p, predictions['p'])\n",
    "        loss.backward()\n",
    "\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if param.requires_grad and param.grad is not None:\n",
    "        #         grads[name] = param.grad\n",
    "        # print(grads)\n",
    "    \n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "    # Average training loss for the epoch\n",
    "    train_losses.append(epoch_train_loss / len(train_loader))\n",
    "    print(f\"Epoch {epoch + 1}: Training Loss = {train_losses[-1]}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    epoch_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{n_epochs} [Validating]\"):\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_p = y_batch[0].to(device)\n",
    "            y_v = y_batch[1].to(device).reshape(-1, 1)\n",
    "            predictions = model(X_batch)\n",
    "            loss = loss_fn(y_v, predictions['v'], y_p, predictions['p'])\n",
    "            epoch_val_loss += loss.item()\n",
    "\n",
    "    # Average validation loss for the epoch\n",
    "    val_losses.append(epoch_val_loss / len(val_loader))\n",
    "    print(f\"Epoch {epoch + 1}: Validation Loss = {val_losses[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1966e51c-26e9-43b7-97db-d339ef43c343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting results\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss During Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0506321-5ed2-42ab-97ab-c69f68c7d6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess",
   "language": "python",
   "name": "chess"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
