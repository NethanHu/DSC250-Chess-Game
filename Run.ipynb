{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d191d686-4228-4f20-a393-77b18ac29159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import encoding_tools as EncodingTools\n",
    "\n",
    "from model import ChessNet\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "MODE = \"RELEASE\"  # If in release mode, please comment this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb2115-0e44-4eb6-a765-e32b00c9c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from FEN_to_chessboard import FenToChessBoard\n",
    "from encoder_decoder import *\n",
    "\n",
    "# Pulling in training data using Pandas\n",
    "df = pd.concat([\n",
    "    pd.read_csv('stockfish_data/chess_games_1.csv'),\n",
    "    pd.read_csv('stockfish_data/chess_games_2.csv'),\n",
    "    pd.read_csv('stockfish_data/chess_games_2.csv')]\n",
    ")\n",
    "\n",
    "non_zero_winners = df.copy()\n",
    "# non_zero_winners = df[df['Winner'] != 0].copy()\n",
    "non_zero_winners.reset_index(drop=True, inplace=True)\n",
    "print(\"Game with an existed winner:\", non_zero_winners.shape) # (18830, 4)\n",
    "\n",
    "train_df = non_zero_winners[:5000] if MODE == \"DEBUG\" else non_zero_winners[:270000]\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "# We'll also grab the last 1000 examples as a validation set\n",
    "val_df = non_zero_winners[-1000:] if MODE == \"DEBUG\" else non_zero_winners[-30000:]\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "##### Package the training data\n",
    "\n",
    "X_train = np.stack(train_df['FEN'].apply(FenToChessBoard.fen_to_board).apply(encode_board)).reshape(-1, 22, 8, 8) # Size(5000, 22, 8, 8)\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "\n",
    "train_best_move_embedding = []\n",
    "for idx, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"[TrainSet] BestMove to embedding\"):\n",
    "    fen_str = row['FEN']\n",
    "    move_str = row['BestMove']\n",
    "    # Check if fen_str is a valid string before processing\n",
    "    if not isinstance(fen_str, str):\n",
    "        raise ValueError(f\"Invalid FEN string at index {idx}: {fen_str}\")\n",
    "    board = FenToChessBoard.fen_to_board(fen_str)\n",
    "    train_best_move_embedding.append(move_on_board(board, move_str))\n",
    "train_best_move_embedding = np.array(train_best_move_embedding)\n",
    "print(\"Embedded Best move shape:\", train_best_move_embedding.shape)\n",
    "y_train = {'best_move' : train_best_move_embedding, 'winner' : train_df['Winner']}\n",
    "\n",
    "\n",
    "##### Package the validation data\n",
    "\n",
    "X_val = np.stack(val_df['FEN'].apply(FenToChessBoard.fen_to_board).apply(encode_board)).reshape(-1, 22, 8, 8)\n",
    "print(\"Validation set size:\", X_val.shape)\n",
    "\n",
    "val_best_move_embedding = []\n",
    "for idx, row in tqdm(val_df.iterrows(), total=len(val_df), desc=\"[ValSet] BestMove to embedding\"):\n",
    "    fen_str = row['FEN']\n",
    "    move_str = row['BestMove']\n",
    "    # Check if fen_str is a valid string before processing\n",
    "    if not isinstance(fen_str, str):\n",
    "        raise ValueError(f\"Invalid FEN string at index {idx}: {fen_str}\")\n",
    "    board = FenToChessBoard.fen_to_board(fen_str)\n",
    "    val_best_move_embedding.append(move_on_board(board, move_str))\n",
    "val_best_move_embedding = np.array(val_best_move_embedding)\n",
    "X_val_cur_board = np.stack(val_df['FEN'].apply(FenToChessBoard.fen_to_board))\n",
    "y_val = {'best_move' : val_best_move_embedding, 'winner' : val_df['Winner']}\n",
    "print(\"Datasets are prepared, you are all set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e523c7-1b66-479d-8d3b-00aa586c1d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = ChessNet()\n",
    "\n",
    "# Move tensors to device if CUDA or MPS is available\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "# elif torch.mps.is_available(): # For M series chips of Mac\n",
    "#     device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "if device == \"cuda\":\n",
    "    # 获取当前GPU名字\n",
    "    gpu_name = torch.cuda.get_device_name(torch.cuda.current_device())\n",
    "    # 获取当前GPU总显存\n",
    "    props = torch.cuda.get_device_properties(device)\n",
    "    total_memory = props.total_memory / 1e9\n",
    "\n",
    "    print(\"当前 GPU 型号是：{}，可用总显存为：{} GB\".format(gpu_name, total_memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a91df04-c5b1-4210-a14a-34bf47439e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ChessDataset\n",
    "\n",
    "# Create Dataset objects for training and validation\n",
    "train_dataset = ChessDataset(X_train, y_train)\n",
    "val_dataset = ChessDataset(X_val, y_val)\n",
    "\n",
    "# Create DataLoaders for batching\n",
    "batch_size = 3000\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for X_batch, y_batch in train_loader:\n",
    "    # 获取一个批次的数据\n",
    "    best_move_batch, winner_batch = y_batch  # 拆分 y_batch\n",
    "    print(\"X_batch shape:\", X_batch.shape)  # 打印 X 的维度\n",
    "    print(\"best_move shape:\", best_move_batch.shape)  # 打印 best_move 的维度\n",
    "    print(\"winner shape:\", winner_batch.shape)  # 打印 winner 的维度\n",
    "    break  # 打印一个批次后停止"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2dfe29-27aa-42cf-9dc9-c35ebc312ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from train import AlphaLoss\n",
    "\n",
    "n_epochs = 40\n",
    "learning_rate = 0.0001 # 0.003 —> 0.0001\n",
    "train_losses, val_losses = [], []\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = AlphaLoss().to(device)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    epoch_train_loss = 0\n",
    "\n",
    "    grads = {}\n",
    "    for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{n_epochs} [Training]\"):\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_p = y_batch[0].to(device)\n",
    "        y_v = y_batch[1].to(device).reshape(-1, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_batch)\n",
    "        loss = loss_fn(y_v, predictions['v'], y_p, predictions['p'])\n",
    "        loss.backward()\n",
    "\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if param.requires_grad and param.grad is not None:\n",
    "        #         grads[name] = param.grad\n",
    "        # print(grads)\n",
    "    \n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "    # Average training loss for the epoch\n",
    "    train_losses.append(epoch_train_loss / len(train_loader))\n",
    "    print(f\"Epoch {epoch + 1}: Training Loss = {train_losses[-1]}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    epoch_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{n_epochs} [Validating]\"):\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_p = y_batch[0].to(device)\n",
    "            y_v = y_batch[1].to(device).reshape(-1, 1)\n",
    "            predictions = model(X_batch)\n",
    "            loss = loss_fn(y_v, predictions['v'], y_p, predictions['p'])\n",
    "            epoch_val_loss += loss.item()\n",
    "\n",
    "    # Average validation loss for the epoch\n",
    "    val_losses.append(epoch_val_loss / len(val_loader))\n",
    "    print(f\"Epoch {epoch + 1}: Validation Loss = {val_losses[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1966e51c-26e9-43b7-97db-d339ef43c343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting results\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss During Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0506321-5ed2-42ab-97ab-c69f68c7d6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess",
   "language": "python",
   "name": "chess"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
